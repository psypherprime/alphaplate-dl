{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:53.905761Z",
     "start_time": "2024-07-06T14:04:53.874480Z"
    }
   },
   "source": "import numpy as np",
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.125166Z",
     "start_time": "2024-07-06T14:04:54.094380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Operation(object):\n",
    "    '''\n",
    "    Base class for all operations in a\n",
    "    neural network.\n",
    "    \n",
    "    Created since the other operations classes are\n",
    "    going to inherit from this class.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input_:np.ndarray):\n",
    "        self.input_ = input_\n",
    "        self.output = self._output()\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        assert self.output.shape == output_grad.shape\n",
    "        self.input_grad = self._input_grad(output_grad) # Check this out\n",
    "        \n",
    "        assert self.input_.shape == self.input_grad.shape\n",
    "        return self.input_grad\n",
    "    \n",
    "    def _output(self) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _input_grad(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError"
   ],
   "id": "6fe534ff302bb68e",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.344557Z",
     "start_time": "2024-07-06T14:04:54.312908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ParamOperation(Operation):\n",
    "    \n",
    "    def __init__(self, param:np.ndarray) -> np.ndarray:\n",
    "        super().__init__()\n",
    "        self.param = param\n",
    "        \n",
    "    def backward(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        assert self.output.shape == output_grad.shape\n",
    "        \n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "        self.param_grad = self._param_grad(output_grad)\n",
    "        \n",
    "        assert self.input_.shape == self.input_grad.shape\n",
    "        assert self.param.shape == self.param_grad.shape\n",
    "        \n",
    "        return self.input_grad\n",
    "    \n",
    "    def _param_grad(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError"
   ],
   "id": "c784789cd234d9d8",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.411744Z",
     "start_time": "2024-07-06T14:04:54.396133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WeightMultiply(ParamOperation):\n",
    "    \n",
    "    def __init__(self, W:np.ndarray) -> np.ndarray:\n",
    "        super().__init__(W)\n",
    "        \n",
    "    def _output(self) -> np.ndarray:\n",
    "        return np.dot(self.input_, self.param)\n",
    "    \n",
    "    def _input_grad(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        return np.dot(output_grad, self.param.T)\n",
    "    \n",
    "    def _param_grad(self, output_grad:np.ndarray) -> np.ndarray: # Check this\n",
    "        return np.dot(self.input_.T, output_grad)"
   ],
   "id": "2a6617a9d3053720",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.458330Z",
     "start_time": "2024-07-06T14:04:54.447360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BiasAdd(ParamOperation):\n",
    "    \n",
    "    def __init__(self, B:np.ndarray):\n",
    "        # assert B[0].shape == 1\n",
    "        super().__init__(B)\n",
    "        \n",
    "    def _output(self) -> np.ndarray:\n",
    "        return self.input_ + self.param\n",
    "    \n",
    "    def _input_grad(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        return np.ones_like(self.input_) * output_grad\n",
    "    \n",
    "    def _param_grad(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        param_grad = np.ones_like(self.param) * output_grad\n",
    "        return np.sum(param_grad, axis=0).reshape(1, param_grad.shape[1])"
   ],
   "id": "ea11ce936315c5de",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.584103Z",
     "start_time": "2024-07-06T14:04:54.574786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sigmoid(Operation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def _output(self) -> np.ndarray:\n",
    "        return 1.0/(1+np.exp(-1.0 * self.input_))\n",
    "    \n",
    "    def _input_grad(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        sigmoid_backward = self.output * (1.0 - self.output)\n",
    "        input_grad = sigmoid_backward * output_grad\n",
    "        return input_grad"
   ],
   "id": "6a8b1c175b3567ed",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.678722Z",
     "start_time": "2024-07-06T14:04:54.665731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Operation):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def _output(self) -> np.ndarray:\n",
    "        return self.input_\n",
    "    \n",
    "    def _input_grad(self, output_grad:np.ndarray) -> np.ndarray:\n",
    "        return output_grad"
   ],
   "id": "7e51335f233aa902",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.773279Z",
     "start_time": "2024-07-06T14:04:54.761279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self,neurons: int):\n",
    "        self.neurons = neurons\n",
    "        self.first = True\n",
    "        self.params: list[np.ndarray] = []\n",
    "        self.param_grads: list[np.ndarray] = []\n",
    "        self.operations: list[Operation] = []\n",
    "        \n",
    "\n",
    "    def _setup_layer(self, num_in: int) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, input_: np.ndarray) -> np.ndarray:\n",
    "        if self.first:\n",
    "            self._setup_layer(input_)\n",
    "            self.first = False\n",
    "\n",
    "        self.input_ = input_\n",
    "\n",
    "        for operation in self.operations:\n",
    "            input_ = operation.forward(input_)\n",
    "\n",
    "        self.output = input_\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_grad: np.ndarray) -> np.ndarray:\n",
    "        assert self.output.shape == output_grad.shape\n",
    "\n",
    "        for operation in reversed(self.operations):\n",
    "            output_grad = operation.backward(output_grad)\n",
    "\n",
    "        input_grad = output_grad\n",
    "        self._param_grads()\n",
    "\n",
    "        return input_grad\n",
    "\n",
    "    def _param_grads(self) -> np.ndarray:\n",
    "        \n",
    "        self.param_grads = []\n",
    "        for operation in self.operations:\n",
    "            if issubclass(operation.__class__, ParamOperation):\n",
    "                self.param_grads.append(operation.param_grad)\n",
    "\n",
    "    def _params(self) -> np.ndarray:\n",
    "        self.params = []\n",
    "        for operation in self.operations:\n",
    "            if issubclass(operation.__class__, ParamOperation):\n",
    "                self.params.append(operation.param)"
   ],
   "id": "d0137be23e24e60b",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.820785Z",
     "start_time": "2024-07-06T14:04:54.802276Z"
    }
   },
   "cell_type": "code",
   "source": [
    " class Dense(Layer):\n",
    "    def __init__(self, neurons: int, activation: Operation=Sigmoid()) -> None:\n",
    "        super().__init__(neurons)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def _setup_layer(self, input_: np.ndarray) -> None:\n",
    "        if self.seed:\n",
    "            np.random.seed(self.seed)\n",
    "            \n",
    "        self.params = []\n",
    "        self.params.append(np.random.randn(input_.shape[1], self.neurons))\n",
    "        self.params.append(np.random.randn(1, self.neurons))\n",
    "        \n",
    "        self.operations = [WeightMultiply(self.params[0]),\n",
    "                           BiasAdd(self.params[1]),\n",
    "                           self.activation]\n",
    "                           \n",
    "        return None\n",
    "    \n",
    "    "
   ],
   "id": "5eb73f32c3cc0da4",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:54.916810Z",
     "start_time": "2024-07-06T14:04:54.904829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, prediction: np.ndarray, target: np.ndarray) -> float:\n",
    "        assert prediction.shape == target.shape\n",
    "        \n",
    "        self.prediction = prediction\n",
    "        self.target = target\n",
    "        \n",
    "        loss_value = self._output()\n",
    "        \n",
    "        return loss_value\n",
    "    \n",
    "    def backward(self) -> np.ndarray:\n",
    "        \n",
    "        self.input_grad = self._input_grad()\n",
    "        assert self.prediction.shape == self.input_grad.shape\n",
    "        \n",
    "        return self.input_grad\n",
    "    \n",
    "    def _output(self) -> float:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _input_grad(self) -> np.ndarray:\n",
    "        raise NotImplementedError"
   ],
   "id": "f5c7379f6d85b2c3",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.011079Z",
     "start_time": "2024-07-06T14:04:54.998080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MeanSquaredError(Loss):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "    def _output(self) -> float:\n",
    "        loss = np.sum(np.square(self.prediction - self.target))/self.prediction.shape[0]\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _input_grad(self) -> np.ndarray:\n",
    "        return 2.0 * (self.prediction - self.target)/self.prediction.shape[0]"
   ],
   "id": "69a3f2dc42cd3514",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.136298Z",
     "start_time": "2024-07-06T14:04:55.107931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, layers: list[Layer], loss: Loss, seed:float = 1):\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.seed = seed\n",
    "        \n",
    "        if seed:\n",
    "            for layer in self.layers:\n",
    "                setattr(layer, \"seed\", self.seed)\n",
    "                \n",
    "    def forward(self, x_batch: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        x_out = x_batch\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x_out = layer.forward(x_out)\n",
    "            \n",
    "        return x_out\n",
    "    \n",
    "    def backward(self, loss_grad: np.ndarray) -> None:\n",
    "        \n",
    "        grad = loss_grad\n",
    "        \n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def train_batch(self, x_batch: np.ndarray, y_batch: np.ndarray) -> float:\n",
    "        \n",
    "        predictions = self.forward(x_batch)\n",
    "        \n",
    "        loss = self.loss.forward(predictions, y_batch)\n",
    "        \n",
    "        self.backward(self.loss.backward())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def params(self):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            yield from layer.params # Issue Here\n",
    "            \n",
    "    def param_grads(self):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            yield from layer.param_grads"
   ],
   "id": "a57c321920444cd3",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.152301Z",
     "start_time": "2024-07-06T14:04:55.143303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Optimizer(object):\n",
    "    \n",
    "    def __init__(self, lr: float = 1e-2):\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self) -> None:\n",
    "        pass"
   ],
   "id": "2ae50dda9494984e",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.199640Z",
     "start_time": "2024-07-06T14:04:55.185609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGD(Optimizer):\n",
    "    \n",
    "    def __init__(self, lr: float = 1e-2) -> None:\n",
    "        super().__init__(lr)\n",
    "        \n",
    "    def step(self):\n",
    "        \n",
    "        for (param, param_grad) in zip(self.net.params(), self.net.param_grads()):\n",
    "            param -= self.lr * param_grad"
   ],
   "id": "4eff6068c7c8080f",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.246815Z",
     "start_time": "2024-07-06T14:04:55.231786Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f2a8a3570f0bdad6",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.340225Z",
     "start_time": "2024-07-06T14:04:55.311192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, net: NeuralNetwork, optim: Optimizer):\n",
    "        \n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.best_loss = 1e9\n",
    "        setattr(self.optim, 'net', self.net)\n",
    "        \n",
    "    def generate_batches(self, X: np.ndarray, y: np.ndarray, size:int=32) -> tuple[np.ndarray]:\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "        \n",
    "        N = X.shape[0]\n",
    "        \n",
    "        for ii in range(0, N, size):\n",
    "            X_batch, y_batch = X[ii:ii+size], y[ii:ii+size]\n",
    "            \n",
    "            yield X_batch, y_batch\n",
    "        \n",
    "    def fit(self, X_train:np.ndarray, y_train:np.ndarray, X_test:np.ndarray, y_test:np.ndarray,\n",
    "            epochs:int=100, eval_every:int=10, batch_size:int=32, seed:int=1, restart:bool=False):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        if restart:\n",
    "            for layer in self.net.layers:\n",
    "                layer.first = True\n",
    "            \n",
    "            self.best_loss = 1e9\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            perm = np.random.permutation(X_train.shape[0])\n",
    "            X_train, y_train = X_train[perm], y_train[perm]\n",
    "            \n",
    "            if epoch % eval_every == 0:\n",
    "                last_model = deepcopy(self.net)\n",
    "            batch_generator = self.generate_batches(X_train, y_train, batch_size)\n",
    "            \n",
    "            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "                self.net.train_batch(X_batch, y_batch)\n",
    "                self.optim.step()\n",
    "                \n",
    "                if (epoch+1) % eval_every == 0:\n",
    "                    test_preds = self.net.forward(X_test)\n",
    "                    loss = self.net.loss.forward(test_preds, y_test)\n",
    "                    \n",
    "                    if loss < self.best_loss:\n",
    "                        print(f\"Validation loss after {epoch+1} epochs: {loss:.3f}\")\n",
    "                        self.best_loss = loss\n",
    "                    else:\n",
    "                        print(f\"Loss increased after {epoch+1} epochs: {loss:.3f} final loss is {self.best_loss:.3f}\")\n",
    "                        self.net = last_model\n",
    "                        setattr(self.optim, 'net', self.net)\n",
    "                        break\n",
    "                        \n",
    "                        \n",
    "    def predict(self, X_test:np.ndarray):\n",
    "        return last_model.forward(X_test)"
   ],
   "id": "9c7b765fba5946bc",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.371324Z",
     "start_time": "2024-07-06T14:04:55.350886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prp = NeuralNetwork(\n",
    "    layers=[Dense(neurons=1,activation=Linear())],\n",
    "    loss=MeanSquaredError(),\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "dnn = NeuralNetwork(\n",
    "    layers=[Dense(neurons=16,activation=Sigmoid()),\n",
    "            Dense(neurons=16,activation=Sigmoid()),\n",
    "            Dense(neurons=1,activation=Linear())],\n",
    "    loss=MeanSquaredError(),\n",
    "    seed=7\n",
    ")"
   ],
   "id": "4a3cfc7db6f29986",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.449693Z",
     "start_time": "2024-07-06T14:04:55.420819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california = fetch_california_housing()\n",
    "data, target = california.data, california.target\n",
    "feature = california.feature_names"
   ],
   "id": "1f4c7e24eae0d018",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.513718Z",
     "start_time": "2024-07-06T14:04:55.500724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)"
   ],
   "id": "50fb7e9efe57e383",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.576267Z",
     "start_time": "2024-07-06T14:04:55.564271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mk_2dnp(a: np.ndarray, type:str=\"col\") -> np.ndarray:\n",
    "    \n",
    "    if type == \"col\":\n",
    "        return a.reshape(-1, 1)\n",
    "    else:\n",
    "        return a.reshape(1, -1)"
   ],
   "id": "23b36d2e7162d1e9",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.669872Z",
     "start_time": "2024-07-06T14:04:55.656883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mae(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def rmse(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return np.sqrt(np.mean(np.power(y_true - y_pred, 2)))\n",
    "\n",
    "def eval_regression_model(model: NeuralNetwork, X_test: np.ndarray, y_test: np.ndarray):\n",
    "    preds = model.forward(X_test)\n",
    "    preds = preds.reshape(-1, 1)\n",
    "    print(\"Mean absolute error: {:.2f}\".format(mae(preds, y_test)))\n",
    "    print(\"Root mean squared error {:.2f}\".format(rmse(preds, y_test)))"
   ],
   "id": "3a6fece11f612e24",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.732682Z",
     "start_time": "2024-07-06T14:04:55.719684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=7)\n",
    "\n",
    "y_train, y_test = mk_2dnp(y_train), mk_2dnp(y_test)"
   ],
   "id": "e828215394efdb4e",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:04:55.796659Z",
     "start_time": "2024-07-06T14:04:55.783640Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, y_train.shape",
   "id": "b33f132e4e936723",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16512, 8), (16512, 1))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:06:44.413435Z",
     "start_time": "2024-07-06T14:06:44.404443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlp = NeuralNetwork(\n",
    "    layers=[Dense(neurons=4,activation=Sigmoid()),\n",
    "            Dense(neurons=4,activation=Sigmoid()),\n",
    "            Dense(neurons=1,activation=Linear())],\n",
    "    loss=MeanSquaredError(),\n",
    "    seed=7\n",
    ")"
   ],
   "id": "62731a1123b2ddf7",
   "outputs": [],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:06:54.065426Z",
     "start_time": "2024-07-06T14:06:44.594697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(mlp, SGD(lr=0.01))\n",
    "trainer.fit(X_train, y_train, X_test, y_test, epochs=100, eval_every=10)\n",
    "\n",
    "eval_regression_model(mlp, X_test, y_test)"
   ],
   "id": "e81d11cdd82d6392",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs: 0.512\n",
      "Loss increased after 10 epochs: 0.512 final loss is 0.512\n",
      "Loss increased after 20 epochs: 0.513 final loss is 0.512\n",
      "Loss increased after 30 epochs: 0.513 final loss is 0.512\n",
      "Loss increased after 40 epochs: 0.513 final loss is 0.512\n",
      "Loss increased after 50 epochs: 0.516 final loss is 0.512\n",
      "Validation loss after 60 epochs: 0.512\n",
      "Loss increased after 60 epochs: 0.512 final loss is 0.512\n",
      "Validation loss after 70 epochs: 0.512\n",
      "Validation loss after 70 epochs: 0.512\n",
      "Loss increased after 70 epochs: 0.512 final loss is 0.512\n",
      "Loss increased after 80 epochs: 0.513 final loss is 0.512\n",
      "Loss increased after 90 epochs: 0.513 final loss is 0.512\n",
      "Loss increased after 100 epochs: 0.513 final loss is 0.512\n",
      "Mean absolute error: 0.52\n",
      "Root mean squared error 0.72\n"
     ]
    }
   ],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:07:30.805817Z",
     "start_time": "2024-07-06T14:07:30.778885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = mlp.forward(X_train)\n",
    "\n",
    "for i in range(10):\n",
    "    print(preds[i], y_train[i])"
   ],
   "id": "27e50519e4f5f6bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.01940725] [4.602]\n",
      "[2.02125306] [3.058]\n",
      "[1.65163136] [1.897]\n",
      "[3.47783875] [3.561]\n",
      "[2.28134133] [2.544]\n",
      "[1.39957281] [2.306]\n",
      "[2.33800864] [1.107]\n",
      "[1.23605787] [0.881]\n",
      "[1.34764952] [0.77]\n",
      "[1.26672375] [0.332]\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:05:11.298544Z",
     "start_time": "2024-07-06T14:05:03.110677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer2 = Trainer(dnn, SGD(lr=0.01))\n",
    "trainer2.fit(X_train, y_train, X_test, y_test, epochs=100, eval_every=10)\n",
    "\n",
    "eval_regression_model(dnn, X_test, y_test)"
   ],
   "id": "2f7230ef7cdac17d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs: 0.447\n",
      "Validation loss after 10 epochs: 0.447\n",
      "Loss increased after 10 epochs: 0.447 final loss is 0.447\n",
      "Validation loss after 20 epochs: 0.447\n",
      "Validation loss after 20 epochs: 0.447\n",
      "Loss increased after 20 epochs: 0.447 final loss is 0.447\n",
      "Loss increased after 30 epochs: 0.448 final loss is 0.447\n",
      "Loss increased after 40 epochs: 0.449 final loss is 0.447\n",
      "Loss increased after 50 epochs: 0.447 final loss is 0.447\n",
      "Loss increased after 60 epochs: 0.447 final loss is 0.447\n",
      "Validation loss after 70 epochs: 0.447\n",
      "Loss increased after 70 epochs: 0.447 final loss is 0.447\n",
      "Loss increased after 80 epochs: 0.453 final loss is 0.447\n",
      "Loss increased after 90 epochs: 0.448 final loss is 0.447\n",
      "Loss increased after 100 epochs: 0.448 final loss is 0.447\n",
      "Mean absolute error: 0.48\n",
      "Root mean squared error 0.67\n"
     ]
    }
   ],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:05:11.345873Z",
     "start_time": "2024-07-06T14:05:11.302545Z"
    }
   },
   "cell_type": "code",
   "source": "dnn.forward(X_test)",
   "id": "a1ff9879b9f7bf7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91125555],\n",
       "       [2.51447649],\n",
       "       [2.81676853],\n",
       "       ...,\n",
       "       [1.17645136],\n",
       "       [2.92560709],\n",
       "       [4.07935367]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:05:11.376919Z",
     "start_time": "2024-07-06T14:05:11.348023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(0,10):\n",
    "    print(y_test[i])"
   ],
   "id": "7d4791f430c62183",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6]\n",
      "[3.36]\n",
      "[2.699]\n",
      "[2.875]\n",
      "[5.00001]\n",
      "[5.00001]\n",
      "[1.602]\n",
      "[0.734]\n",
      "[0.921]\n",
      "[5.00001]\n"
     ]
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:05:11.392926Z",
     "start_time": "2024-07-06T14:05:11.377922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dnn2 = NeuralNetwork(\n",
    "    layers=[Dense(neurons=6,activation=Sigmoid()),\n",
    "            Dense(neurons=6,activation=Sigmoid()),\n",
    "            Dense(neurons=3,activation=Sigmoid()),\n",
    "            Dense(neurons=1,activation=Linear())],\n",
    "    loss=MeanSquaredError(),\n",
    "    seed=7\n",
    ")"
   ],
   "id": "95abe2e48f346bc4",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:05:13.529574Z",
     "start_time": "2024-07-06T14:05:11.394935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(prp, SGD(lr=0.001))\n",
    "trainer.fit(X_train, y_train, X_test, y_test, epochs=100, eval_every=10)\n",
    "\n",
    "eval_regression_model(dnn2, X_test, y_test)"
   ],
   "id": "e3ce72bacee0ab68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs: 0.527\n",
      "Validation loss after 10 epochs: 0.527\n",
      "Validation loss after 10 epochs: 0.527\n",
      "Validation loss after 10 epochs: 0.527\n",
      "Validation loss after 10 epochs: 0.527\n",
      "Loss increased after 10 epochs: 0.527 final loss is 0.527\n",
      "Validation loss after 20 epochs: 0.525\n",
      "Validation loss after 20 epochs: 0.524\n",
      "Loss increased after 20 epochs: 0.524 final loss is 0.524\n",
      "Loss increased after 30 epochs: 0.528 final loss is 0.524\n",
      "Loss increased after 40 epochs: 0.525 final loss is 0.524\n",
      "Loss increased after 50 epochs: 0.528 final loss is 0.524\n",
      "Loss increased after 60 epochs: 0.529 final loss is 0.524\n",
      "Loss increased after 70 epochs: 0.525 final loss is 0.524\n",
      "Loss increased after 80 epochs: 0.529 final loss is 0.524\n",
      "Loss increased after 90 epochs: 0.525 final loss is 0.524\n",
      "Loss increased after 100 epochs: 0.525 final loss is 0.524\n",
      "Mean absolute error: 0.91\n",
      "Root mean squared error 1.27\n"
     ]
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:05:13.545176Z",
     "start_time": "2024-07-06T14:05:13.529574Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "66172db3871a1fa",
   "outputs": [],
   "execution_count": 213
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
