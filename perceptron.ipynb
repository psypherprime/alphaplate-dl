{
 "cells": [
  {
   "cell_type": "code",
   "id": "264163b7256360f8",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.247087Z",
     "start_time": "2024-07-03T13:21:45.231756Z"
    }
   },
   "source": "import numpy as np",
   "outputs": [],
   "execution_count": 698
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.262713Z",
     "start_time": "2024-07-03T13:21:45.247087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_linear_regression(X_batch: np.ndarray, y_batch: np.ndarray, weights: dict[str, np.ndarray]) -> tuple[float, dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Implementation of forward pass of the perceptron.\n",
    "    Here, We are calculating the matrices to get the prediction label.\n",
    "    \"\"\"\n",
    "    # Checking if the number of labels is equal to number of inputs\n",
    "    assert X_batch.shape[0] == y_batch.shape[0]\n",
    "    # Checking the dimensions for matrix multiplication\n",
    "    assert X_batch.shape[1] == weights['W'].shape[0]\n",
    "    # Checking that B is 1x1 ndarray\n",
    "    assert weights['B'].shape[0] == weights['B'].shape[1] == 1\n",
    "\n",
    "    N = np.dot(X_batch, weights['W'])\n",
    "    P = N + weights['B']\n",
    "\n",
    "    loss = np.mean(np.square(y_batch - P))\n",
    "    forward_info: dict[str, np.ndarray] = {'X': X_batch, 'N': N, 'P': P, 'y': y_batch}\n",
    "\n",
    "    return loss, forward_info"
   ],
   "id": "8b7561153d0eb908",
   "outputs": [],
   "execution_count": 699
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.278356Z",
     "start_time": "2024-07-03T13:21:45.262713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_gradients(forward_info: dict[str, np.ndarray], weights: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "    batch_size  = forward_info['X'].shape[0]\n",
    "    \"\"\"\n",
    "    dLdW = dLdP * dPdN * dNdW\n",
    "    dLdP = dLdP * dPdB * dBdB\n",
    "    \"\"\"\n",
    "    dLdP = -2 * (forward_info['y'] - forward_info['P'])\n",
    "    dPdN = np.ones_like(forward_info['N'])\n",
    "    dPdB = np.ones_like(weights['B'])\n",
    "\n",
    "    dLdN = dLdP * dPdN\n",
    "    dNdW = np.transpose(forward_info['X'], (1, 0)) # Check this\n",
    "\n",
    "    dLdW = np.dot(dNdW, dLdN)\n",
    "    dLdB = (dLdP * dPdB).sum(axis=0)\n",
    "\n",
    "    loss_gradients: dict[str, np.ndarray] = {'W': dLdW, 'B': dLdB}\n",
    "\n",
    "    return loss_gradients"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 700
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.293961Z",
     "start_time": "2024-07-03T13:21:45.278356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Batch = tuple[np.ndarray, np.ndarray]\n",
    "\n",
    "def generate_batch(X: np.ndarray, y: np.ndarray, start: int = 0, batch_size: int = 32) -> Batch:\n",
    "    # Checking for perceptron requirements and same units\n",
    "    assert X.ndim == y.ndim == 2\n",
    "    \n",
    "    # Controlling overflow\n",
    "    if start + batch_size > X.shape[0]:\n",
    "        batch_size = X.shape[0] - start\n",
    "    \n",
    "    X_batch, y_batch = X[start:start + batch_size], y[start:start + batch_size]\n",
    "    \n",
    "    return X_batch, y_batch"
   ],
   "id": "186343355267cfb5",
   "outputs": [],
   "execution_count": 701
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.309605Z",
     "start_time": "2024-07-03T13:21:45.293961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_loss(X: np.ndarray, y:np.ndarray, weights: dict[str, np.ndarray]) -> tuple[dict[str, np.ndarray], float]:\n",
    "    N = np.dot(X, weights['W'])\n",
    "    P = N + weights['B']\n",
    "    loss = np.mean(np.square(y - P))\n",
    "\n",
    "    forward_info: dict[str, np.ndarray] = {'X': X, 'N': N, 'P': P, 'y': y}\n",
    "\n",
    "    return forward_info, loss"
   ],
   "id": "87fcbf2de82ebec8",
   "outputs": [],
   "execution_count": 702
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.325391Z",
     "start_time": "2024-07-03T13:21:45.309605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_weights(n_in: int) -> dict[str, np.ndarray]:\n",
    "    W = np.random.randn(n_in, 1)\n",
    "    B = np.random.randn(1, 1)\n",
    "    \n",
    "    weights = {'W': W, 'B': B}\n",
    "    \n",
    "    return weights"
   ],
   "id": "f7fa137a5acce0e5",
   "outputs": [],
   "execution_count": 703
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.342488Z",
     "start_time": "2024-07-03T13:21:45.326834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(X: np.ndarray, y: np.ndarray, epochs: int = 100, batch_size: int = 32, learning_rate: float = 0.01,\n",
    "          return_losses:bool = False, return_weights:bool = False, seed: int = 0\n",
    "          ):\n",
    "\n",
    "    if seed != 0:\n",
    "        np.random.seed(seed)\n",
    "    # Shuffling Data\n",
    "    perm = np.random.permutation(X.shape[0])\n",
    "    X, y = X[perm], y[perm]\n",
    "\n",
    "    start = 0\n",
    "    weightst = init_weights(X.shape[1])\n",
    "\n",
    "    if return_losses:\n",
    "        losses = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        if start >= X.shape[0]:\n",
    "            perm = np.random.permutation(X.shape[0])\n",
    "            X, y = X[perm], y[perm]\n",
    "            start = 0\n",
    "\n",
    "        X_batch, y_batch = generate_batch(X, y, start, batch_size)\n",
    "        start += batch_size\n",
    "\n",
    "        forward_info, loss = forward_loss(X_batch, y_batch, weightst)\n",
    "\n",
    "        if return_losses:\n",
    "            losses.append(loss)\n",
    "\n",
    "        loss_grads = loss_gradients(forward_info, weightst)\n",
    "        for key in weightst.keys():\n",
    "            weightst[key] -= (learning_rate * loss_grads[key])\n",
    "\n",
    "        # print(weightst['W'], (learning_rate * loss_grads['W']), weightst['W'] - (learning_rate * loss_grads['W']))\n",
    "\n",
    "    if return_weights:\n",
    "        return losses, weightst\n",
    "\n",
    "    return None"
   ],
   "id": "7f6c63e4b75d690b",
   "outputs": [],
   "execution_count": 704
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.358186Z",
     "start_time": "2024-07-03T13:21:45.342488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target"
   ],
   "id": "2ccde64eae945243",
   "outputs": [],
   "execution_count": 705
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.373712Z",
     "start_time": "2024-07-03T13:21:45.358186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "X = s.fit_transform(X)"
   ],
   "id": "626c7ec4e82be05f",
   "outputs": [],
   "execution_count": 706
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.389333Z",
     "start_time": "2024-07-03T13:21:45.373712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "divd = int(0.7*len(X))\n",
    "X_train, X_test, y_train, y_test = X[:divd], X[divd:], y[:divd], y[divd:]\n",
    "\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)"
   ],
   "id": "cce288053900f0f6",
   "outputs": [],
   "execution_count": 707
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.404962Z",
     "start_time": "2024-07-03T13:21:45.389333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_info = train(X_train, y_train, epochs=100, batch_size=32, learning_rate=0.001, return_losses=True, return_weights=True)\n",
    "losses = train_info[0]\n",
    "weights = train_info[1]"
   ],
   "id": "a14136fd6dd5e8a3",
   "outputs": [],
   "execution_count": 708
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.420587Z",
     "start_time": "2024-07-03T13:21:45.404962Z"
    }
   },
   "cell_type": "code",
   "source": "losses",
   "id": "e7cf011978e437d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(25477.434886902054),\n",
       " np.float64(29290.797073118585),\n",
       " np.float64(18326.806280997233),\n",
       " np.float64(26942.86951368122),\n",
       " np.float64(15057.123416614857),\n",
       " np.float64(13977.44981543089),\n",
       " np.float64(14054.0092655529),\n",
       " np.float64(15803.084195664913),\n",
       " np.float64(12415.167571721078),\n",
       " np.float64(8325.344841622487),\n",
       " np.float64(10193.871089143166),\n",
       " np.float64(7890.100157083074),\n",
       " np.float64(7382.223115985411),\n",
       " np.float64(6984.491191272788),\n",
       " np.float64(7673.452682342233),\n",
       " np.float64(4847.3573996588275),\n",
       " np.float64(6804.3236558200715),\n",
       " np.float64(7551.957018186113),\n",
       " np.float64(6224.476904145541),\n",
       " np.float64(6456.28784463516),\n",
       " np.float64(5621.583808555383),\n",
       " np.float64(5424.442583909335),\n",
       " np.float64(4153.74932347992),\n",
       " np.float64(2995.086668344571),\n",
       " np.float64(3659.081691488398),\n",
       " np.float64(2617.8943270151235),\n",
       " np.float64(3815.253075216295),\n",
       " np.float64(3583.992581811881),\n",
       " np.float64(6009.271556910835),\n",
       " np.float64(4082.597727929987),\n",
       " np.float64(4042.958227320493),\n",
       " np.float64(2281.0304272443077),\n",
       " np.float64(4227.916429558015),\n",
       " np.float64(2794.1089767937297),\n",
       " np.float64(3027.7752008276902),\n",
       " np.float64(3740.535310569924),\n",
       " np.float64(3854.1953481873993),\n",
       " np.float64(2693.917106723554),\n",
       " np.float64(3483.751990786568),\n",
       " np.float64(3093.6650236343044),\n",
       " np.float64(2819.6811554132164),\n",
       " np.float64(4554.754625166645),\n",
       " np.float64(2856.3443114823995),\n",
       " np.float64(4407.317312623965),\n",
       " np.float64(2449.2514430280435),\n",
       " np.float64(2715.7557288525695),\n",
       " np.float64(2676.3117327728987),\n",
       " np.float64(2440.9478046857535),\n",
       " np.float64(3046.6828297594748),\n",
       " np.float64(2682.6484544871814),\n",
       " np.float64(2977.072184720362),\n",
       " np.float64(2044.0220630669287),\n",
       " np.float64(2371.8325782604074),\n",
       " np.float64(2975.6808429571065),\n",
       " np.float64(3816.709410070511),\n",
       " np.float64(3836.6746731424873),\n",
       " np.float64(3860.589817109908),\n",
       " np.float64(2334.790696576014),\n",
       " np.float64(3290.213756723886),\n",
       " np.float64(2689.1733964177006),\n",
       " np.float64(4352.831660689846),\n",
       " np.float64(2786.63329783074),\n",
       " np.float64(2756.838227782755),\n",
       " np.float64(2686.5997336614246),\n",
       " np.float64(2391.4738836368306),\n",
       " np.float64(3018.47257002239),\n",
       " np.float64(3582.6327329276046),\n",
       " np.float64(2317.758357491067),\n",
       " np.float64(2562.9441429411663),\n",
       " np.float64(3719.436612188297),\n",
       " np.float64(4778.9191729357335),\n",
       " np.float64(2774.4185087600918),\n",
       " np.float64(2873.3008613095876),\n",
       " np.float64(2005.4793661706317),\n",
       " np.float64(3324.925742683125),\n",
       " np.float64(2622.724291995206),\n",
       " np.float64(3670.221211344833),\n",
       " np.float64(2599.5174205320154),\n",
       " np.float64(2433.346231565695),\n",
       " np.float64(3102.6170439446105),\n",
       " np.float64(2719.1504296805842),\n",
       " np.float64(3052.3600726839504),\n",
       " np.float64(3251.591457778976),\n",
       " np.float64(2131.5275450407034),\n",
       " np.float64(2513.006165819953),\n",
       " np.float64(3533.9625022527766),\n",
       " np.float64(3340.7916193836527),\n",
       " np.float64(3002.985590538904),\n",
       " np.float64(3303.7936547721397),\n",
       " np.float64(3730.490055479485),\n",
       " np.float64(1827.5858399856875),\n",
       " np.float64(2598.2001614490646),\n",
       " np.float64(2802.849770424063),\n",
       " np.float64(3437.7530248117982),\n",
       " np.float64(3481.429566472123),\n",
       " np.float64(2519.56733359562),\n",
       " np.float64(5418.522763050201),\n",
       " np.float64(2521.3161998834603),\n",
       " np.float64(3406.5159251744894),\n",
       " np.float64(1324.0322949234055)]"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 709
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.436231Z",
     "start_time": "2024-07-03T13:21:45.420587Z"
    }
   },
   "cell_type": "code",
   "source": "weights",
   "id": "7b5b552288ec9d4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W': array([[ -0.20596269],\n",
       "        [-12.96181516],\n",
       "        [ 26.03833422],\n",
       "        [ 13.68219862],\n",
       "        [ -2.93616292],\n",
       "        [ -5.99441123],\n",
       "        [ -9.08201409],\n",
       "        [  6.47473474],\n",
       "        [ 24.40483544],\n",
       "        [  5.36870243]]),\n",
       " 'B': array([[152.8396778]])}"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 710
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:21:45.451833Z",
     "start_time": "2024-07-03T13:21:45.436231Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f204938f89789e22",
   "outputs": [],
   "execution_count": 710
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
